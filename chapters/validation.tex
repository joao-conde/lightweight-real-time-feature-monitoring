\chapter{Method Validation} \label{chap:validation} \minitoc

In order to test our proposed system, we generated multiple synthetic datasets before moving on to real data. As an initial step, we started by validating our system using single-feature datasets before moving to multi-feature scenarios in order to facilitate system validation, considering the complexities of multi-feature datasets and the problem of multiple test correction.


\section{Experiments with synthetic data}
\subsection{Single Feature Analysis}

\subsubsection{Varying sample sizes}
We began with single-feature scenarios and by experimenting with different tuple-based half-lifes $n_{1/2}$ which in turn controls the size of the samples we make. In Section \ref{sec:ema-hist}, we mentioned we discarded events whose contribution was less than 6\%. We set a half-life $n_{1/2}$ value and then multiply it by a constant factor of 4 to get the size of the samples to make (a larger sample would contain events whose contribution was equal or less than 6\%).

The reference dataset R1 used in this first experiment contained a single feature that followed a normal distribution with mean $\mu=10$ and standard deviation $\sigma=2$ for the 5 million rows of the dataset. Figure \ref{fig:timeseries-r1} shows the time-series of the single feature in dataset R1.
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/01-reference.png}
      \caption[]{Time-series for dataset R1}
      \label{fig:timeseries-r1}
    \end{center}
\end{figure}
The dataset used to process as a data stream or the target dataset also had 5 million events with a single feature. For the first half, \textit{i.e.}, for the first 2.5 million events, the feature followed a normal distribution with mean $\mu=10$ and standard deviation $\sigma=2$, like the reference dataset. For the other half, we changed the generating distribution to be a continuous uniform one with lower bound $a=100$ and upper bound $b=200$. Figure \ref{fig:timeseries-t1} shows the time-series of the single feature in the target dataset T1 where we see the abrupt change in feature values.
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/01-target.png}
      \caption[]{Time-series for dataset T1}
      \label{fig:timeseries-t1}
    \end{center}
\end{figure}

We conducted three different experiments varying the tuple-based half-life $n_{1/2}$, using the reference dataset R1 and the target dataset T1. These experiments, corresponding varying half-lifes and execution times are shown in Table \ref{tbl:tests-half-life}. Notice that $Sample Size$ corresponds to the size of each sample made in the batch phase and will be four times the half-life. We used 100 bins (plus the two special infinity bins) for the reference histogram and made 1000 samples.
\begin{table}[!htb]
    \begin{center}
        \begin{tabular}{|c|c|c|c|c|}
        \hline
        \multicolumn{1}{|l|}{\textbf{Experiment}} & \multicolumn{1}{l|}{\textbf{Half-life}} & \multicolumn{1}{l|}{\textbf{Sample Size}} & \multicolumn{1}{l|}{\textbf{Executors}} & \multicolumn{1}{l|}{\textbf{Batch execution time (seconds)}} \\ \hline
        01                                        & 625                                     & 2500                                      & 300                                     & 152                                                          \\ \hline
        02                                        & 62,500                                  & 250,000                                   & 300                                     & 2,822                                                        \\ \hline
        03                                        & 250,000                                 & 1,000,000                                 & 300                                     & 10,082                                                       \\ \hline
        \end{tabular}
    \end{center}
    \caption{Experiments with varying half-life}
    \label{tbl:tests-half-life}
\end{table}
7 6 8
Table \ref{tbl:tests-half-life} shows the execution time for the batch phase in seconds. All experiments used 300 Spark executor instances. The batch phase comprises more than the sampling process but the remaining tasks take the same time across experiment. From the Table we conclude that the larger the half-life, the larger the sample size. Larger samples imply longer processing times when computing the EMA-like histogram for each sample. With no surprise, we see that the larger the sample the longer it takes to finish the batch phase.

From a functional point of view, were we able to detect the abrupt change introduced in the target dataset T1? Recall that from the 2.5 millionth event forward we change the distribution from a gaussian to an uniform one (Figure \ref{fig:timeseries-t1}). Figure \ref{fig:JSD-signal-01} shows the distance (JSD) values computed during streaming at each event of the 5 million events from dataset T1, using the outputs from the batch phase of experiment 01. We clearly see a change in JSD values, and we move from values close to 0 to values close to 1 (or even 1). Figure \ref{fig:JSD-signal-zoom-01} shows the same signal but for the first half of the streaming period (essentially a zoom-in). We see our JSD values before the change were very low (magnitudes of $10^{-2}$).
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/stream-analysis-viz-625.png}
      \caption[]{Distance (JSD) signal and threshold for experiment 01}
      \label{fig:JSD-signal-01}
    \end{center}
\end{figure}
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/stream-analysis-viz-zoom-625.png}
      \caption[]{Zoomed in distance (JSD) signal and threshold for experiment 01}
      \label{fig:JSD-signal-zoom-01}
    \end{center}
\end{figure}
However, the change in JSD value is very abrupt as well. Almost instantly we go from close to 0 values to 1. We also had some false-positives, \textit{i.e.}, some JSD values above the threshold. This indicates to us that the window used is too small and sensible to small changes.

In experiment 02, we use larger sampling windows. Remember our target sliding window in streaming is of the same size as the sampling windows. In the second experiment, we increase the size of the sampling and target windows by 100 times.

Figure \ref{fig:JSD-signal-02} shows the JSD signal during streaming for dataset T1, using the outputs from the batch phase of experiment 02. Again, we see a change in signal from the middle of the streaming period forward. Figure \ref{fig:JSD-signal-zoom-02} shows the same signal for the first half of the streaming period.
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/stream-analysis-viz-62500.png}
      \caption[]{Distance (JSD) signal and threshold for experiment 02}
      \label{fig:JSD-signal-02}
    \end{center}
\end{figure}
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/stream-analysis-viz-zoom-62500.png}
      \caption[]{Zoomed in distance (JSD) signal and threshold for experiment 02}
      \label{fig:JSD-signal-zoom-02}
    \end{center}
\end{figure}
Notice that this time the growth of our signal is slower. Notice also that we don not have false positives in the first half of the signal. This is because we use a larger window, which means each event has a smaller contribution to the aggregation state. Hence, outliers will have less impact on the aggregation and corresponding signal value.

In experiment 03, we increase the sampling and target windows size once again, this time four times larger than in experiment 02. We would expect an even smoother growth of our signal and, again, no false positives. And indeed, judging by the corresponding signal computation and zoom-in, Figures \ref{fig:JSD-signal-03} and \ref{fig:JSD-signal-zoom-03}, respectively, the signal looks smoother and we see no false positives.
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/stream-analysis-viz-250000.png}
      \caption[]{Distance (JSD) signal and threshold for experiment 03}
      \label{fig:JSD-signal-03}
    \end{center}
\end{figure}
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/stream-analysis-viz-zoom-250000.png}
      \caption[]{Zoomed in distance (JSD) signal and threshold for experiment 03}
      \label{fig:JSD-signal-zoom-03}
    \end{center}
\end{figure}


\subsubsection{Multiple distribution changes, each contained within the previous one}
In this experiment, we wanted to see how our signal behaved when there were multiple change points, where each distribution was contained within the previous one. Figure \ref{fig:timeseries-r2} shows the time-series for the reference dataset R2 used in this experiment. It contained 5 million events with a single feature following a gaussian distribution with mean $\mu=100$ and standard deviation $\sigma=50$.
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/timeseries-r2.png}
      \caption[]{Time-series for dataset R2}
      \label{fig:timeseries-r2}
    \end{center}
\end{figure}
The time-series for target dataset T2 is shown in Figure \ref{fig:timeseries-t2}. Notice that we change distributions at 2, 3 and 4 millionth events. Notice also that each subsequent distribution produces values whose domain is a subset of the previous distribution. 
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/timeseries-t2.png}
      \caption[]{Time-series for dataset T2}
      \label{fig:timeseries-t2}
    \end{center}
\end{figure}

The target dataset T2 begins with the same distribution as the reference dataset R2, a gaussian distribution with mean $\mu=100$ and standard deviation $\sigma=50$. At the 2 millionth event mark we use another gaussian distribution, this time with mean $\mu=100$ and standard deviation $\sigma=30$. At the 3 millionth event we change the standard deviation to be $\sigma=10$. From the 4 millionth event till the end, we use a standard deviation of $\sigma=5$. 

In this experiment, we used a half-life $n_{1/2}=62500$ and corresponding sample size of 250,000 events, like in the previous Section' experiment 02. Figure \ref{fig:JSD-signal-test02} shows the computed JSD signal for the target dataset and Figure \ref{fig:JSD-signal-zoom-test02} zooms in on the first 2 millionth events, before any distribution is changed. We observe that once again we have no false positives in the first 2 million events, which is ideal. 
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/stream-analysis-viz-test02.png}
      \caption[]{Distance (JSD) signal and threshold}
      \label{fig:JSD-signal-test02}
    \end{center}
\end{figure}
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/stream-analysis-viz-zoom-test02.png}
      \caption[]{Zoomed in distance (JSD) signal and threshold}
      \label{fig:JSD-signal-zoom-test02}
    \end{center}
\end{figure}
Furthermore, we observe that the computed JSD signal varies accordingly with the changes in distribution. Despite us changing the distributions to subsets of the previous ones to try and deceive our method, our signal accurately represents these changes. In Figure \ref{fig:JSD-signal-test02}, we see several growth points that correspond to the points where the generating gaussian distribution parameters changed. Hence, we are able to detect changes in distribution parameter changes and quantify how big the change is (the closer to 1 our signal is).

\subsubsection{Multiple distribution changes, each a superset of the previous one}

In this experiment, we wanted to do the reverse of the previous one. In this one, there are multiple change points but each new distribution is a superset of the previous one. Figure \ref{fig:timeseries-r3} shows the reference period used, with 5 million events and one feature following a gaussian distribution of mean $\mu=100$ and standard deviation $\sigma=10$.
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/timeseries-r3.png}
      \caption[]{Time-series for dataset R3}
      \label{fig:timeseries-r3}
    \end{center}
\end{figure}
Figure \ref{fig:timeseries-t3} shows the target period used, also with 5 million events and one feature. Like in the previous experiment, we change distributions at the 2, 3 and 4 millionth event mark. On the other hand, unlike the previous experiment, we now make subsequent distributions cover the previous ones. We change the reference gaussian used with mean $\mu=100$ and standard deviation $\sigma=10$ at the 2, 3 and 4 millionth mark, to use standard deviations $\sigma=30$, $\sigma=40$ and $\sigma=50$, respectively.
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/timeseries-t3.png}
      \caption[]{Time-series for dataset T3}
      \label{fig:timeseries-t3}
    \end{center}
\end{figure}

Figure \ref{fig:JSD-signal-test03} shows the JSD signal for the target dataset in this experiment. Once again, we were able to detect the changes introduced at the 2, 3 and 4 millionth events. We are also able to identify bigger distribution changes, relative to the reference, by observing bigger JSD values.
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/stream-analysis-viz-test03.png}
      \caption[]{Distance (JSD) signal and threshold}
      \label{fig:JSD-signal-test03}
    \end{center}
\end{figure}
Figure \ref{fig:JSD-signal-zoom-test03} shows a zoomed in portion of the original signal, where we can verify that there are no false positives.
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/stream-analysis-viz-zoom-test03.png}
      \caption[]{Zoomed in distance (JSD) signal and threshold}
      \label{fig:JSD-signal-zoom-test03}
    \end{center}
\end{figure}


\subsubsection{Return to normality after change}
Our goal with this experiment was to check if our signal returned to its normal values (below the alert threshold) if we changed our distribution to the original reference one, as intended.

In this experiment, we used reference dataset R4 (Figure \ref{fig:timeseries-r4}) and target dataset T4 (Figure \ref{fig:timeseries-t4}). 
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/timeseries-r4.png}
      \caption[]{Time-series for dataset R4}
      \label{fig:timeseries-r4}
    \end{center}
\end{figure}
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/timeseries-t4.png}
      \caption[]{Time-series for dataset T4}
      \label{fig:timeseries-t4}
    \end{center}
\end{figure}

The reference dataset R4 had a single feature that followed a gaussian distribution of $\mu=100$ and $\sigma=5$ for all 5 million events. Up until the 2 millionth event, the target dataset T4 followed a gaussian distribution of $\mu=100$ and $\sigma=5$, similarly to the reference dataset R4. At the 2 millionth event, we change the gaussian parameters to $\mu=100$ and $\sigma=30$. At the 3 millionth mark, we once again change the gaussian parameters to $\mu=100$ and $\sigma=50$. Finally, on the 4 millionth event, we return to our reference distribution, a gaussian with $\mu=100$ and $\sigma=5$.


Figure \ref{fig:JSD-signal-test04} shows the computed JSD signal for the target period.
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/stream-analysis-viz-test04.png}
      \caption[]{Distance (JSD) signal and threshold}
      \label{fig:JSD-signal-test04}
    \end{center}
\end{figure}

As expected, our JSD signal increases at the 2 millionth and 3 millionth event marks, because the distribution parameters change. At the 4 millionth event, we use the original reference distribution and notice that the JSD signal returns to values below the threshold, considering it a normal state, as we intended. Figure \ref{fig:JSD-signal-zoom-test04} is a zoom in on the first 2 millionth events, before any change occurs, and we see no false positives.
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/stream-analysis-viz-zoom-test04.png}
      \caption[]{Zoomed in distance (JSD) signal and threshold}
      \label{fig:JSD-signal-zoom-test04}
    \end{center}
\end{figure}

\subsubsection{An attempt to deceive our method}
In this experiment, we attempt to deceive our method by using a different distribution from the reference period but ensuring its domain is roughly the same as the reference one.

We used the reference dataset R5 (Figure \ref{fig:timeseries-r5}) which had 5 million events, with a single-feature that followed a gaussian with  $\mu=100$ and $\sigma=10$.
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/timeseries-r5.png}
      \caption[]{Time-series for dataset R5}
      \label{fig:timeseries-r5}
    \end{center}
\end{figure}

Our target dataset T5 is represented in Figure \ref{fig:timeseries-t5}. For the first 2 million events, the generating distribution used was similar to the one used in the reference dataset, a gaussian with $\mu=100$ and $\sigma=10$. However, at the 2 millionth event, we change the gaussian standard deviation to $\sigma=30$. Then, at the 4 millionth event, we change the distribution type. We use an uniform distribution with lower bound $a=80$ and upper bound $b=120$. Note in Figure \ref{fig:timeseries-t5} that this last portion resembles the first one, the reference.
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/timeseries-t5.png}
      \caption[]{Time-series for dataset T5}
      \label{fig:timeseries-t5}
    \end{center}
\end{figure}


Let's take a look at the signal computed for the target period. Figure \ref{fig:JSD-signal-test05} shows us the JSD signal for dataset T5 \ref{fig:timeseries-t5}. As expected, we see a rapid growth of JSD value after the 2 millionth event, when we change the gaussian parameters. We then change the distribution type, from a gaussian to a uniform one. Despite the latter having the a domain contained within the former, we see that our signal is accurate and does not drop below the alert threshold. This is still a different distribution that we want to alert. 
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/stream-analysis-viz-test05.png}
      \caption[]{Distance (JSD) signal and threshold}
      \label{fig:JSD-signal-test05}
    \end{center}
\end{figure}

Figure \ref{fig:JSD-signal-zoom-test05} is a zoom in of the first 2 millionth events and once again we have no false positives.
\begin{figure}[!htb]
    \begin{center}
      \includegraphics[scale=0.6]{figures/stream-analysis-viz-zoom-test05.png}
      \caption[]{Zoomed in distance (JSD) signal and threshold}
      \label{fig:JSD-signal-zoom-test05}
    \end{center}
\end{figure}

\subsection{Multi Feature Analysis}
Before moving to real data, we performed one last experiment, using synthetic data but this time performing a multi-feature analysis. Table \ref{tbl:multi-feat-ref-dataset-distros} shows the distributions and their parameters for each of the four features (x1, x2, x3 and x4) present in the reference multi-feature dataset R6. Figures \ref{fig:timeseries-r6-x1}, \ref{fig:timeseries-r6-x2}, \ref{fig:timeseries-r6-x3} and \ref{fig:timeseries-r6-x4} show the reference time-series for features x1, x2, x3 and x4 on the reference dataset R6, respectively.

\begin{table}[!htb]
    \begin{center}
        \begin{tabular}{|c|c|c|ll}
        \cline{1-3}
        \textbf{Feature} & \textbf{Reference Distribution} & \textbf{Parameters} &  &  \\ \cline{1-3}
        x1               & Gaussian/Normal                 & $\mu=100$, $\sigma=5$  &  &  \\ \cline{1-3}
        x2               & Gaussian/Normal                 & $\mu=100$, $\sigma=5$  &  &  \\ \cline{1-3}
        x3               & Uniform                         & $a=200$, $b=250$       &  &  \\ \cline{1-3}
        x4               & Uniform                         & $a=50$, $b=125$        &  &  \\ \cline{1-3}
        \end{tabular}
    \end{center}
    \caption{Multi feature reference dataset and feature distributions}
    \label{tbl:multi-feat-ref-dataset-distros}
\end{table}


\begin{figure}[!htb] 
  \begin{minipage}[b]{0.5\linewidth}
    \centering
    \includegraphics[width=1\linewidth]{figures/timeseries-r6-x1.png} 
    \caption{Feature x1 reference time-series} 
    \label{fig:timeseries-r6-x1} 
    \vspace{4ex}
  \end{minipage}%%
  \begin{minipage}[b]{0.5\linewidth}
    \centering
    \includegraphics[width=1\linewidth]{figures/timeseries-r6-x2.png} 
    \caption{Feature x2 reference time-series} 
    \label{fig:timeseries-r6-x2} 
    \vspace{4ex}
  \end{minipage} 
  \begin{minipage}[b]{0.5\linewidth}
    \centering
    \includegraphics[width=1\linewidth]{figures/timeseries-r6-x3.png} 
    \caption{Feature x3 reference time-series} 
    \label{fig:timeseries-r6-x3} 
    \vspace{4ex}
  \end{minipage}%% 
  \begin{minipage}[b]{0.5\linewidth}
    \centering
    \includegraphics[width=1\linewidth]{figures/timeseries-r6-x4.png} 
    \caption{Feature x4 reference time-series} 
    \label{fig:timeseries-r6-x4} 
    \vspace{4ex}
  \end{minipage} 
\end{figure}

We used a target dataset T6 with 5 million events and the same four features (x1, x2, x3 and x4). Feature x1 followed the reference distribution for the 5 million events of the target dataset. We did not change this feature underlying distribution so as to serve as control, \textit{i.e.}, we expect no alerts for this one. Figure \ref{fig:timeseries-t6-x1} shows the time-series for the target dataset T6 and feature x1. 

Feature x2's underlying distribution changed four times and returned to normal, so we expect to see alarms with increasing divergence values but eventually no more alarms. Figure \ref{fig:timeseries-t6-x2} shows the time-series for the target dataset T6 and feature x2. Feature x2 followed a gaussian with $\mu=100$ and $\sigma=5$ like in the reference period up to the 1 millionth event mark, then a gaussian with $\mu=100$ and $\sigma=10$ up to the 2.5 millionth event, then a gaussian $\mu=100$ and $\sigma=15$ until the 3 millionth event, then a gaussian $\mu=100$ and $\sigma=20$ until the 4 millionth event and finally returned to the original gaussian with $\mu=100$ and $\sigma=5$ until the last event.

Feature x3's underlying distribution changed three times and never returned to normal, so we expect to see alarms with increasing divergence values up until the end of the stream analysis. Figure \ref{fig:timeseries-t6-x3} shows the time-series for the target dataset T6 and feature x3. Feature x3 followed a uniform distribution with $a=200$ and $b=250$ like in the reference period up to the 1.5 millionth event mark, then a uniform distribution with $a=200$ and $b=220$ up to the 2 millionth event, then a uniform distribution with $a=180$ and $b=200$ until the 3.5 millionth event and finally a gaussian with $\mu=50$ and $\sigma=20$ until the last event.

Feature x4's underlying distribution changed two times and returned to normal, so we expect to see no alarms towards the end of the stream analysis. Figure \ref{fig:timeseries-t6-x4} shows the time-series for the target dataset T6 and feature x4. Feature x4 followed a uniform distribution like the reference one, with $a=50$ and $b=125$ up until the 1.5 millionth event. After that, it followed a uniform distribution with $a=125$ and $b=200$ until the 3 millionth event where it resumed its original uniform distribution (with $a=50$ and $b=125$) until the end.

\begin{figure}[!htb] 
  \begin{minipage}[b]{0.5\linewidth}
    \centering
    \includegraphics[width=1\linewidth]{figures/timeseries-t6-x1.png} 
    \caption{Feature x1 target time-series} 
    \label{fig:timeseries-t6-x1} 
    \vspace{4ex}
  \end{minipage}%%
  \begin{minipage}[b]{0.5\linewidth}
    \centering
    \includegraphics[width=1\linewidth]{figures/timeseries-t6-x2.png} 
    \caption{Feature x2 target time-series} 
    \label{fig:timeseries-t6-x2} 
    \vspace{4ex}
  \end{minipage} 
  \begin{minipage}[b]{0.5\linewidth}
    \centering
    \includegraphics[width=1\linewidth]{figures/timeseries-t6-x3.png} 
    \caption{Feature x3 target time-series} 
    \label{fig:timeseries-t6-x3} 
    \vspace{4ex}
  \end{minipage}%% 
  \begin{minipage}[b]{0.5\linewidth}
    \centering
    \includegraphics[width=1\linewidth]{figures/timeseries-t6-x4.png} 
    \caption{Feature x4 target time-series} 
    \label{fig:timeseries-t6-x4} 
    \vspace{4ex}
  \end{minipage} 
\end{figure}

In this experiment, we used a tuple-based half-life $n_{1/2}=62500$, \textit{i.e.} sampling and target windows of 250,000 tuples. We used 100 bins for the reference histogram plus the two special infinity bins. In this multi-feature scenario, we used the Holm-Bonferroni correction discussed in Section \ref{sec:holmbonferroni} and set the Family-Wise Error Rate (FWER) to 1\% (FWER = 0.01). Furthermore, instead of performing ad-hoc 1000 samples like we did previosuly, we use Equation \ref{eq:optimal-n-samples} to determine the minimum number of samples to make while ensuring $\gamma=1\%$ (recall Section \ref{sec:nsamples}). For our four feature analysis scenario, using as inputs  $\gamma=0.01$ and $FWER=0.01$ in Equation \ref{eq:optimal-n-samples} tells us we need to make 1840 samples minimum.


LOOK INTO EVERY1000.TXT AND COMMENT ALERT RESULTS.
SPECIFY THAT THIS PERIOD IS AD-HOC
